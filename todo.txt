List of things to do on the hearts game:	

1) Investigate whether there is a bias for order of Hearts players
	-> There should be no bias at all, all spots should perform equally well

2) Do some checks on the backpropagation to ensure that the scores are correct.
	-> Remeber that a node has its own score as well as the score of the nodes below it.

3) Implement UCT in implementation 1 of MCTS
	-> http://senseis.xmp.net/?UCT for info and pseudocode
	-> Perform tests!

4) Continue testing some of the implementations you have - if results are inconcistent, ask yourself why. (Could just be from randomness)

6) REDO THE APP FOR TESTING PURPOSES
	-> Should be testing all values on same hands
	-> Should be recording results so you can find SD
	-> Could be useful to practice getting these results into excel
	-> If you build a prototype results collector, you'll have less work to do later on

7) Test for coefficient and thresehold in UCT
	-> Record how you did it and the results you found
	-> Write up for report?
-------------------------------------------------------------------------------

SCHEUDLE:

13th August - Have finished the 2 distinct implementations
27th August - Have 3rd implementation finished
1st September - Finish testing environment and ALL CODING
15th September - First draft of final report submitted
22nd September - Second draft of final report submitted
3rd October - Final copy of report submitted

-------------------------------------------------------------------------------

REPORT NOTES:

Include a paragraph of some general findings / decisions regarding...
	-> UCT Parameters
		-> Coeefficient
		-> Thresehold
	-> Number of tests (found with SD)
	-> Amount of time given to the MCTS algorithm

Include in future work a discussion on the advantages of card counting / more soft information, since your focus was not on that.

-------------------------------------------------------------------------------

AFTER FIRST METHOD TESTING:
Since the end of the first implementation is approaching, we have to consider what implementation will be implemented next. After some testing / discussion with Michael Albert, coding for the second implementation should begin.

-------------------------------------------------------------------------------

IDEAS FOR SECOND IMPLEMENTATION:

1) Currently, one MCTS is drawn and at each node a simulate play method is completed, each with a different random set of cards.
	-> Instead of having one tree, have multiple
	-> The tree assigns hands at the start, then traverses
	-> Caluclate the best trees as opposed to best nodes

2) Implement the UCT algorithm for the Select method.

3) Improve the DoubleDummy playout with more advanced logic
	-> E.g. play highest card unless winning trick
	-> Maybe try to get rid of one suit first

4) Add an option for the DoubleDummy simulation to have preset players as the logic
	-> Make modular

-------------------------------------------------------------------------------

IDEAS FOR THIRD IMPLEMENTATION:

1) Introduce more hard and soft information
	-> e.g. card counting and prediction

-------------------------------------------------------------------------------

SOME NOTES:

-------------------------------------------------------------------------------

IMPLEMENTATION 0: Current improvement over random 3-4%

SELECT METHOD:

Currently, the select method works in a very naive fashion.
For each node, we calculate the average score of that node,
and then we subtract this from 13 to get X. We then add
X + 1 of the node to an array.

Once we have done this for all nodes, we randomly select from
this array. This is a very simple approach for biasing nodes
with a low average score.

EXPANSION METHOD:

Creates child nodes based on the card that can be played at the node.
	-> Represents a PLAY, not the whole trick

SIMULATE METHOD:

Upon reaching a node to begin a random simulation...
	-> Remove previously played cards from hand
	-> Randomly remove the equivalent number of opponents cards from remaining deck
	-> Randomly deal hands to the opponents
	-> Begin a "DoubleDumy" playout under these conditions
		-> DoubleDummy very naive, based on some simple rules
		-> Will try avoid trick if Hearts, otherwise win
		-> Does not support half made tricks
		-> How significant will improvements be on this?
	-> Simple algorithm - if no Hearts, play highest card, else lowest
	-> Record results

BACKPROPAGATE METHOD:

Basic backprop, adding score and visit count to previous nodes.

-------------------------------------------------------------------------------

IMPLEMENTATION 1: Current improvement over random 9-10%

SELECT METHOD:
	-> UCT with chosen parameters

EXPANSION METHOD:

SIMULATE METHOD:

Number of improvements to the DoubleDummy playouts:
	-> Randomised the start player (when no current trick passed) rather than assuming the player would start
	-> Added support for halfway through trick
	-> Potential TODO: change how the algorithm responds to playing different players

BACKPROPAGATE METHOD:

-------------------------------------------------------------------------------

IMPLEMENTATION IDEAS:

* Make a hand represent a trick as opposed to just a hand

* Swap out the tree approach - instead of one tree with random deals at nodes, have multiple
  trees that define a permanent deal at the root. Calculate the best move from the most common
  move returned from the trees.

-------------------------------------------------------------------------------

MISC NOTES / OBSERVATIONS:

* Had to randomise the start player for low trick games
	-> It seems that the start player has a disadvantage, assumed to be
	   because other players could not follow suit.

* Simply improving the DoubleDummy playout method had a huge improvement over performance,
  suggesting that a great deal of the MCTS capability relies on the DoubleDummy method itself.

-------------------------------------------------------------------------------

EVALUATION METHODS

There are three main methods that are to be used in the evaluation of the algorithms.
Each of these methods assumes 6 player types.
	1) Random
	2) Basic Player (Rule based)
	3) Advanced Player (Rule based)
	4) MCTS Implementation 0
	5) MCTS Implementation 1
	6) MCTS Implementation 2

Also to note, we need to retain the most information possible - probably results of each game
copyed into a program like excel.

METHOD 1

Say we wish to compare our players.

We playout some number of games with random deals (say 1000). Each player plays against
3 other random opponents, and we look at the average number of Hearts collected. The same
hands / games need to be played out by all players (not a different random game for each player).

Once we have this information, we can then look at the difference in average Hearts collected
in a graph format.

We can then place the difference in a table like this...

	1	2	3
1	0.2	1	0.6 	...

2	1	2	0.8	...

3	3.4	5	0.7	...



METHOD 2:

From the above table, we may choose to look at some of the bigger differences in more detail.

We can then play a player against X Y and Z, where XYZ are players from our player pool, and we
can investigate how well they do against other player types.

METHOD 3:

When looking at MCTS specifically, we can make a graph of performance to timer varaible - as we increase
how much time we are giving the algorithm, our results should also improve.

OTHER METHODS:

We can consider other methods, for example comparing components of MCTS, as we wish. But we should start
with the main methods above.






















